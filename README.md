# Dense_vector_embedding_example
The google colab file provides example codes for demonstrating the use of dense vector embeddings concerning the following applications.

- Semantic Similarity with sentence-transformers.  

- Q&A retrieval using Facebook AI’s DPR model.  

- Image-text matching with OpenAI’s CLIP.  

The examples are quite basic and defined in a straightaway manner. The idea is to just perhaps highlight the advancements of transformer embeddings in the field of Natural Language Processing and Computer vision. 

Following packages are needed.

sentence-transformers

transformers

PIL

requests

numpy

matplotlib.pyplot

*All the images used in the colab file are from google images. 

The references of the methods used in this study are shown below.

[1] T. Mikolov, et al., Efficient Estimation of Word Representations in Vector Space (2013)

[2] T. Mikolov, et al., Linguistic Regularities in Continuous Space Word Representations (2013), NAACL HLT

[3] M. Alcorn, (batter|pitcher)2vec: Statistic-Free Talent Modeling With Neural Player Embeddings (2017), MIT Sloan: Sports Analytics Conference

[4] N. Reimers, I. Girevych, Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks (2019), EMNLP

[5] N. Reimers, SentenceTransformers Documentation, sbert.net

[6] V. Karpukhin, et al., Dense Passage Retrieval for Open-Domain Question Answering (2020), EMNLP

[7] L. H. Li, et al., VisualBERT: A Simple and Performant Baseline for Vision and Language (2019), arXiv

[8] A. Dosovitskiy, et al., An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (2020), arXiv

[9] A. Radford, et al., CLIP: Connecting Text and Images (2021), OpenAI Blog

[10] CLIP Model Card, Hugging Face
